{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c274df-5df3-4406-9790-f59380bcf177",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import cmasher as cmr\n",
    "except:\n",
    "    !pip install cmasher\n",
    "    import cmasher as cmr\n",
    "\n",
    "try:\n",
    "    import afterglowpy as grb\n",
    "except:\n",
    "    !pip install afterglowpy\n",
    "    import afterglowpy as grb\n",
    "    \n",
    "try:\n",
    "    import emcee\n",
    "except:\n",
    "    !pip install emcee\n",
    "    import emcee\n",
    "    \n",
    "try:\n",
    "    import corner\n",
    "except:\n",
    "    !pip install corner\n",
    "    import corner\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from vasttools.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize, curve_fit\n",
    "import scipy.stats\n",
    "from IPython.display import display, Math\n",
    "from astropy.coordinates import Distance\n",
    "from astropy import units as u\n",
    "from astropy.coordinates import Angle\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ae03a1-908f-4dd5-8a73-6dcb0fa5987a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_to_time(name):\n",
    "    name = name.lstrip('GW').split('_')\n",
    "    if len(name) == 1:\n",
    "        return pd.to_datetime(name[0], format='%y%m%d').to_datetime64()\n",
    "    return pd.to_datetime(name[0] + name[1], format='%y%m%d%H%M%S').to_datetime64()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b6ee4c-dade-4e47-b26d-38b41d4ec08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline()\n",
    "piperun = pipe.load_run('combined')\n",
    "# meas = piperun.measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0c06ab-2bf0-4d76-9140-3022dbce08ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def afterglowpy_log_likelihood(theta, Z, Z_static, t, y, yerr):\n",
    "    model = grb.fluxDensity(t, 888.0e6, **Z_static, **dict(zip(Z.keys(), theta)))\n",
    "    inv_sigma2 = 1/yerr**2\n",
    "    res = -0.5*(np.sum((y-model)**2*inv_sigma2 - np.log(inv_sigma2)))\n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "def afterglowpy_log_prior(theta):\n",
    "    thetaObs, thetaCore, n0, p, epsilon_e, epsilon_B = theta\n",
    "    if 0 <= thetaObs <= np.pi/2 \\\n",
    "      and 0 <= thetaCore <= np.pi/2 \\\n",
    "      and 0 < n0 <1 \\\n",
    "      and 2 < p \\\n",
    "      and 0 <= epsilon_e <= 1 \\\n",
    "      and 0 <= epsilon_B <= 1:\n",
    "        return 0.0\n",
    "    return -np.inf\n",
    "\n",
    "\n",
    "\n",
    "def afterglowpy_log_probability(theta, Z, Z_static, t, y, yerr):\n",
    "    lp = afterglowpy_log_prior(theta)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    return lp + afterglowpy_log_likelihood(theta, Z, Z_static, t, y, yerr)\n",
    "\n",
    "\n",
    "\n",
    "def afterglowpy_make_chain_plot(chain, chain_cut, save_plots, fname):\n",
    "    niters = chain.shape[1]\n",
    "    ndim = chain.shape[2]\n",
    "\n",
    "    fig, axes = plt.subplots(ndim,1,sharex=True)\n",
    "    fig.set_size_inches(7, 20)\n",
    "    \n",
    "    param_names = ['$\\\\theta_{\\\\rm obs}$', '$\\\\theta_{\\\\rm core}$','$n_0$','$p$', '$\\\\epsilon_{e}$', '$\\\\epsilon_{B}$', '$d_{L}$']\n",
    "\n",
    "    for i, (ax,param_name) in enumerate(zip(axes,param_names)):\n",
    "        ax.plot(chain[:,:,i].T,linestyle='-',color='k',alpha=0.3)\n",
    "        ax.set_ylabel(param_name)\n",
    "        ax.set_xlim(0,niters)\n",
    "        ax.axvline(chain_cut,c='r',linestyle='--')\n",
    "    plt.show()\n",
    "    if save_plots:\n",
    "        plt.savefig(f'{fname}_afterglowpy_chain.png', dpi=200)\n",
    "    \n",
    "    \n",
    "def afterglowpy_make_corner_plot(good_chain, fname, save_plots):\n",
    "    param_names = ['$\\\\theta_{\\\\rm obs}$', '$\\\\theta_{\\\\rm core}$','$n_0$','$p$', '$\\\\epsilon_{e}$', '$\\\\epsilon_{B}$', 'd_{L}']\n",
    "    ndim = good_chain.shape[2]\n",
    "    fig = corner.corner(good_chain.reshape((-1, ndim)), labels=param_names, quantiles=[0.16, 0.5, 0.84], show_titles=True)\n",
    "    plt.show()\n",
    "    if save_plots:\n",
    "        plt.savefig(f'{fname}_afterglowpy_corner.png', dpi=200)\n",
    "\n",
    "        \n",
    "\n",
    "def afterglowpy_get_starting_pos(starting_vals, nwalkers):\n",
    "    thetaObs, thetaCore, n0, p, epsilon_e, epsilon_B = starting_vals  \n",
    "    pos = [np.asarray([thetaObs, thetaCore, n0, p, epsilon_e, epsilon_B]) + 1e-4*np.random.randn(len(starting_vals)) for i in range(nwalkers)]\n",
    "    return pos\n",
    "\n",
    "\n",
    "\n",
    "def afterglowpy_run_mcmc(Z, Z_static, t, y, yerr, starting_vals, niters, nwalkers):\n",
    "    nu = 0.888\n",
    "    \n",
    "    pos = afterglowpy_get_starting_pos(starting_vals, nwalkers)\n",
    "    \n",
    "    sampler = emcee.EnsembleSampler(\n",
    "        nwalkers,\n",
    "        len(starting_vals),\n",
    "        afterglowpy_log_probability,\n",
    "        args=(Z, Z_static, t, y, yerr)\n",
    "    )\n",
    "    \n",
    "    sampler.run_mcmc(pos, niters, progress=True)\n",
    "    \n",
    "    return sampler\n",
    "\n",
    "\n",
    "\n",
    "def fit_afterglowpy(source, event, mean, save_plots=False, fname=None, epoch_indices='all', niters=1000, nwalkers=50):\n",
    "    \"\"\"\n",
    "    Fit the source measurements to an afterglowpy grb lightcurve via MCMC.\n",
    "\n",
    "        Parameters:\n",
    "            source (vasttools.source.Source): the VAST source object\n",
    "            event_time (datetime64): the GW event time as a datetime64 object\n",
    "            mean (float): the mean distance luminosity of the GW event in Mpc\n",
    "            fname (bool): plot prefix name (default None)\n",
    "            save_plots (bool): whether to save the produced plots (default false)\n",
    "            epoch_indices ('all' or list): a list of epoch indices to fit the curve to (default 'all')\n",
    "            niters (int): number of iterations to run MCMC (default 1000)\n",
    "            nwalkers(int): number of walkers in MCMC (default 50)\n",
    "    \"\"\"\n",
    "    Z = {\n",
    "        'thetaObs': 0.05,\n",
    "        'thetaCore': 0.1,\n",
    "        'n0': 1.0,\n",
    "        'p': 2.2,\n",
    "        'epsilon_e': 0.1,\n",
    "        'epsilon_B': 0.01}\n",
    "    \n",
    "    Z_static = {\n",
    "    'jetType': -1,\n",
    "    'specType': 0,\n",
    "    'xi_N': 1.0,\n",
    "    'L0': 0.0, \n",
    "    'q': 0.0,\n",
    "    'ts': 0.0,\n",
    "    'E0': 1e+53,\n",
    "    'd_L': mean*u.Mpc.to('cm')\n",
    "    }\n",
    "    \n",
    "    source_meas = source.measurements\n",
    "    event_time = name_to_time(event)\n",
    "    after_meas = source_meas.iloc[np.where(source_meas.dateobs>event_time)[0]]\n",
    "    \n",
    "    if epoch_indices == 'all':\n",
    "        x = np.array((after_meas.dateobs-event_time)/pd.Timedelta(1, unit='d'))\n",
    "        y = after_meas.flux_peak\n",
    "        yerr = after_meas.flux_peak_err\n",
    "    else:\n",
    "        x = ((after_meas.dateobs-event_time)/pd.Timedelta(1, unit='d')).values[epoch_indices]\n",
    "        y = after_meas.flux_peak.values[epoch_indices]\n",
    "        yerr = after_meas.flux_peak_err.values[epoch_indices]\n",
    "\n",
    "    t=pd.to_timedelta(x, unit='D').total_seconds()\n",
    "    nu = np.empty(t.shape)\n",
    "    nu[:] = 888.0e6\n",
    "    \n",
    "    starting_vals = np.fromiter(Z.values(), dtype=float)\n",
    "    pos = afterglowpy_get_starting_pos(starting_vals, nwalkers)\n",
    "\n",
    "    sampler = afterglowpy_run_mcmc(Z, Z_static, t, y, yerr, starting_vals, niters, nwalkers)\n",
    "    chain = sampler.chain\n",
    "    \n",
    "    \n",
    "    chain_cut = 200\n",
    "    afterglowpy_make_chain_plot(chain, chain_cut, save_plots=save_plots, fname=fname)\n",
    "    \n",
    "    good_chain = chain[:, chain_cut:, :]\n",
    "    afterglowpy_make_corner_plot(good_chain, save_plots=save_plots, fname=fname)\n",
    "    \n",
    "    \n",
    "    flat_samples = sampler.get_chain(discard=chain_cut, thin=15, flat=True)\n",
    "    inds = np.random.randint(len(flat_samples), size=10)\n",
    "    for ind in inds:\n",
    "        sample = flat_samples[ind]\n",
    "        new_y = grb.fluxDensity(t, nu, **Z_static, **dict(zip(Z.keys(), sample)))\n",
    "        plt.scatter(x, new_y)\n",
    "    plt.errorbar(x, y, yerr=yerr, fmt=\".k\", capsize=0)\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fce313-9e37-414e-8395-8bff4522d8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_broken_power_law(t, nu, F_peak, t_peak, delta_1, delta_2, alpha, log_s, nu0=3.0):\n",
    "    s = 10**log_s\n",
    "    return (nu/nu0)**alpha * F_peak * ((t/t_peak)**(-s*delta_1) + (t/t_peak)**(-s*delta_2))**(-1.0/s)\n",
    "\n",
    "\n",
    "\n",
    "def bpl_log_likelihood(theta, x, nu, y, yerr, inv_sigma2):\n",
    "    F_peak, t_peak, delta_1, delta_2, alpha, log_s = theta\n",
    "    model = smooth_broken_power_law(x, nu, F_peak, t_peak, delta_1, delta_2, alpha, log_s)\n",
    "    res = -0.5*(np.sum((y-model)**2*inv_sigma2 - np.log(inv_sigma2)))\n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "def bpl_log_prior(theta, time_peak_limit):\n",
    "    F_peak, t_peak, delta_1, delta_2, alpha, log_s = theta\n",
    "    \n",
    "    if 0 < t_peak < time_peak_limit \\\n",
    "      and 0 < F_peak \\\n",
    "      and 0 < delta_1 \\\n",
    "      and delta_2 < 0.0 \\\n",
    "      and -10 < alpha \\\n",
    "      and np.isfinite(log_s) \\\n",
    "      and log_s < 10:\n",
    "        return 0.0\n",
    "    \n",
    "    else:\n",
    "        return -np.inf\n",
    "\n",
    "\n",
    "\n",
    "def bpl_log_probability(theta, x, nu, y, yerr, inv_sigma2, time_peak_limit):\n",
    "    lp = bpl_log_prior(theta, time_peak_limit)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    return lp + bpl_log_likelihood(theta, x, nu, y, yerr, inv_sigma2)\n",
    "\n",
    "\n",
    "\n",
    "def bpl_make_chain_plot(chain, chain_cut, fname, save_plots, param_names=[]):\n",
    "    niters = chain.shape[1]\n",
    "    ndim = chain.shape[2]\n",
    "\n",
    "    fig, axes = plt.subplots(ndim,1,sharex=True)\n",
    "    fig.set_size_inches(7, 20)\n",
    "    \n",
    "    param_names = ['$F_{{\\\\rm peak}, 3\\.{\\\\rm GHz}}$', '$t_{{\\\\rm peak}}$','$\\\\delta_1$','$\\\\delta_2$', '$\\\\alpha$', '$\\\\log_{10}(s)$']\n",
    "\n",
    "    for i, (ax,param_name) in enumerate(zip(axes,param_names)):\n",
    "        ax.plot(chain[:,:,i].T,linestyle='-',color='k',alpha=0.3)\n",
    "        ax.set_ylabel(param_name)\n",
    "        ax.set_xlim(0,niters)\n",
    "        ax.axvline(chain_cut,c='r',linestyle='--')\n",
    "    plt.show()\n",
    "    if save_plots:\n",
    "        plt.savefig(f'{fname}_power_law_chain.png', dpi=200)\n",
    "\n",
    "    \n",
    "    \n",
    "def bpl_make_corner_plot(good_chain, save_plots, fname):\n",
    "    param_names = ['$F_{{\\\\rm peak}, 3\\.{\\\\rm GHz}}$', '$t_{{\\\\rm peak}}$','$\\\\delta_1$','$\\\\delta_2$', '$\\\\alpha$', '$\\\\log_{10}(s)$']\n",
    "    ndim = good_chain.shape[2]\n",
    "    fig = corner.corner(good_chain.reshape((-1, ndim)), labels=param_names, quantiles=[0.16, 0.5, 0.84], show_titles=True)\n",
    "    plt.show()\n",
    "    if save_plots:\n",
    "        plt.savefig(f'{fname}_power_law_corner.png', dpi=200)\n",
    "    \n",
    "    \n",
    "    \n",
    "def bpl_get_starting_pos(starting_vals, nwalkers, ndim=6):\n",
    "    F_peak, t_peak, delta_1, delta_2, alpha, log_s = starting_vals  \n",
    "    pos = [np.asarray([F_peak, t_peak, delta_1, delta_2, alpha, log_s]) + 1e-4*np.random.randn(ndim) for i in range(nwalkers)]\n",
    "    return pos\n",
    "\n",
    "\n",
    "\n",
    "def bpl_run_mcmc(x, y, yerr, starting_vals, niters, nwalkers, time_peak_limit):\n",
    "    nu = 0.888\n",
    "    inv_sigma2 = 1.0/yerr**2\n",
    "    \n",
    "    pos = bpl_get_starting_pos(starting_vals, nwalkers, ndim)\n",
    "    \n",
    "    sampler = emcee.EnsembleSampler(nwalkers, len(starting_vals), bpl_log_probability, args=(x, nu, y, yerr, inv_sigma2, time_peak_limit))\n",
    "    \n",
    "    sampler.run_mcmc(pos, niters, progress=True)\n",
    "    \n",
    "    return sampler\n",
    "\n",
    "\n",
    "\n",
    "def bpl_get_best_params(chain):\n",
    "    ndim = chain.shape[2]\n",
    "    \n",
    "    chain = chain.reshape((-1, ndim))\n",
    "    vals = map(lambda v: (v[1], v[2]-v[1], v[1]-v[0]), zip(*np.percentile(chain, [16, 50, 84],axis=0)))\n",
    "    \n",
    "    param_names = ['F_peak', 't_peak', 'delta_1', 'delta_2', 'alpha', 'log_s']\n",
    "    \n",
    "    param_dict = dict(zip(param_names,vals))\n",
    "    \n",
    "    return param_dict\n",
    "    \n",
    "\n",
    "\n",
    "def calc_chi2(x, y, yerr, best_params, param_names, model, nu0=3.0):\n",
    "    \"\"\"Calculates chi-squared between a set of measurements and a model\"\"\"\n",
    "    args = []\n",
    "    for param in param_names:\n",
    "        val = best_params[param][0]\n",
    "        args.append(val)\n",
    "\n",
    "    best_fit = model(x, 0.888, *args)\n",
    "    \n",
    "    chi2 = np.sum((best_fit-y)**2/yerr**2)\n",
    "    return chi2\n",
    "\n",
    "\n",
    "\n",
    "def bpl_make_plot(x, y, yerr, save_plots, fname, model=None, params=None, tvals=np.arange(10,400), plot_models=False):\n",
    "    \"\"\"Make broken power law plot\"\"\"\n",
    "    fig = plt.figure(figsize=(10,6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    ax.errorbar(x, y, yerr, linestyle='')\n",
    "    \n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    \n",
    "    ax.set_xlabel('Time (days)')\n",
    "\n",
    "    ax.set_ylabel('Flux Density ($\\mu$Jy)')\n",
    "        \n",
    "    if model:\n",
    "        plot_model(model, params, tvals, ax)\n",
    "    \n",
    "    ax.set_xlim(min(x)/1.2,max(x)*1.2)\n",
    "    plt.show()\n",
    "    if save_plots:\n",
    "        plt.savefig(f'{fname}_fitted_power_law.png', dpi=200)\n",
    "\n",
    "    \n",
    "\n",
    "def plot_model(model, params, tvals, ax):\n",
    "    \"\"\"Add a model lightcurve to a plot\"\"\"\n",
    "    best_fit = model(tvals, 0.888, *params)\n",
    "    \n",
    "    ax.plot(tvals,best_fit,marker='',linestyle='-',c='k',linewidth=1.5,zorder=0)\n",
    "    ax.set_ylim(bottom=0.2)\n",
    "    ax.set_xscale('log')\n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "def fit_bpl(source, event, mean, fname=None, save_plots=False, epoch_indices='all', niters=1000, nwalkers=50):\n",
    "    \"\"\"\n",
    "    Fit the source measurements to a broken power law lightcurve via MCMC.\n",
    "    \n",
    "        Parameters:\n",
    "            source (vasttools.source.Source): the VAST source object\n",
    "            event_time (datetime64): the GW event time as a datetime64 object\n",
    "            mean (float): the mean distance luminosity of the GW event in Mpc\n",
    "            fname (bool): plot prefix name (default None)\n",
    "            save_plots (bool): whether to save the produced plots (default false)\n",
    "            epoch_indices ('all' or list): a list of epoch indices to fit the curve to (default 'all')\n",
    "            niters (int): number of iterations to run MCMC (default 1000)\n",
    "            nwalkers(int): number of walkers in MCMC (default 50)\n",
    "    \"\"\"\n",
    "    event_time = name_to_time(event)\n",
    "    source_meas = source.measurements\n",
    "    after_meas = source_meas.iloc[np.where(source_meas.dateobs>event_time)[0]]\n",
    "    \n",
    "    if epoch_indices == 'all':\n",
    "        x = np.array((after_meas.dateobs-event_time)/pd.Timedelta(1, unit='d'))\n",
    "        y = after_meas.flux_peak\n",
    "        yerr = after_meas.flux_peak_err\n",
    "    else:\n",
    "        x = ((after_meas.dateobs-event_time)/pd.Timedelta(1, unit='d')).values[epoch_indices]\n",
    "        y = after_meas.flux_peak.values[epoch_indices]\n",
    "        yerr = after_meas.flux_peak_err.values[epoch_indices]\n",
    "        \n",
    "    \n",
    "    time_peak_limit = x[np.argmax(y)+1]\n",
    "    \n",
    "    starting_vals = {\n",
    "        'F_peak': max(y),\n",
    "        't_peak': x[np.argmax(y)],\n",
    "        'delta_1': 1,\n",
    "        'delta_2': -1,\n",
    "        'alpha': 1,\n",
    "        'log_s': 1}\n",
    "    \n",
    "    \n",
    "    sampler = bpl_run_mcmc(x, y, yerr, starting_vals.values(), niters, nwalkers,time_peak_limit)\n",
    "    chain = sampler.chain\n",
    "    \n",
    "    chain_cut = 200\n",
    "    bpl_make_chain_plot(chain, chain_cut, save_plots=save_plots, fname=fname)\n",
    "    \n",
    "    good_chain = chain[:, chain_cut:, :]\n",
    "    bpl_make_corner_plot(good_chain, save_plots=save_plots, fname=fname)\n",
    "    \n",
    "    best_params = bpl_get_best_params(good_chain)\n",
    "    \n",
    "    param_names = ['F_peak', 't_peak', 'delta_1', 'delta_2', 'alpha', 'log_s']\n",
    "\n",
    "    chi2_best = calc_chi2(x, y, yerr, best_params, param_names, smooth_broken_power_law)\n",
    "    print(chi2_best)\n",
    "    \n",
    "    args = []\n",
    "    for param in param_names:\n",
    "        val = best_params[param][0]\n",
    "        args.append(val)\n",
    "\n",
    "    bpl_make_plot(x, y, yerr, tvals = np.arange(min(x)-10, max(x)+100), model=smooth_broken_power_law, params=args, save_plots=save_plots, fname=fname)\n",
    "    return chi2_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0de7140-31c9-4229-a952-d8ecba019d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plot(E_iso_vals, dist_vals, theta_vals, n_vals, fname, save_plots, alpha=0.3):\n",
    "    colours = cmr.take_cmap_colors('cmr.rainforest', 3, cmap_range=(0.3,0.7), return_fmt='hex')\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    ax.set_xlim(0,np.pi/2)\n",
    "#     ax.set_ylim(1e-6, 1e1)\n",
    "    ax.set_ylim(1e-3, 1e1)\n",
    "    ax.set_yscale('log')\n",
    "    \n",
    "    ax.set_xlabel(r'$\\theta_{\\rm obs}$ (rad)')\n",
    "    ax.set_ylabel(r'$n$ (cm$^{-3}$)')\n",
    "    \n",
    "#     ax.axvline(np.rad2deg(theta_median), c='k')\n",
    "#     ax.axvline(np.rad2deg(theta_median-theta_lower), c='k', ls='--')\n",
    "#     ax.axvline(np.rad2deg(theta_median+theta_upper), c='k', ls='--')\n",
    "\n",
    "\n",
    "    for E_iso, col in zip(E_iso_vals, colours):\n",
    "        full_lims = []\n",
    "        for dist in dist_vals:\n",
    "            picklefile = 'pickles/{}_Eiso{}_d{}.pickle'.format(fname, E_iso, dist.value)\n",
    "            lims = get_lims(picklefile)\n",
    "            if lims is not None:\n",
    "                full_lims.append(lims)\n",
    "        if len(full_lims) != 2:\n",
    "            continue\n",
    "        label='$E_{{\\\\rm iso}}=${} erg'.format(E_iso)\n",
    "\n",
    "        ax.fill_between(theta_vals, n_vals[full_lims[0]], n_vals[full_lims[1]], color=col, alpha=alpha, label=label)\n",
    "\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    if save_plots:\n",
    "        plt.savefig(f'{fname}_constraints.png', dpi=200)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "def get_lims(picklefile):\n",
    "    try:\n",
    "        ruled_out = pickle.load(open(picklefile, 'rb'))\n",
    "    except:\n",
    "        return None\n",
    "    lim = ruled_out.argmax(axis=1)\n",
    "    return lim\n",
    "\n",
    "\n",
    "\n",
    "def run_calc(t, nu, upper_lims, E_iso_vals, dist_vals, theta_vals, n_vals, Z_static, fname):\n",
    "    for E_iso in E_iso_vals:\n",
    "        for dist in dist_vals:\n",
    "            print(\"Calculating lightcurves for E_iso={} ergs, d_L={}\".format(E_iso, dist))\n",
    "            picklefile = 'pickles/{}_Eiso{}_d{}.pickle'.format(fname, E_iso, dist.value)\n",
    "            ruled_out = np.empty(shape=(len(theta_vals), len(n_vals)), dtype=bool)\n",
    "            for i, theta_obs in enumerate(tqdm(theta_vals)):\n",
    "                for j, n in enumerate(n_vals):\n",
    "                    Fnu = grb.fluxDensity(\n",
    "                        t,\n",
    "                        nu,\n",
    "                        E0=E_iso,\n",
    "                        d_L=dist.to(u.cm).value,\n",
    "                        thetaObs=theta_obs,\n",
    "                        n0=n,\n",
    "                        **Z_static\n",
    "                        )\n",
    "                    \n",
    "                    ruled_out[i,j] = np.count_nonzero(Fnu>=upper_lims) >= 2\n",
    "            pickle.dump(ruled_out, open(picklefile, 'wb'))\n",
    "            \n",
    "            \n",
    "            \n",
    "def get_constraints(\n",
    "    source,\n",
    "    event,\n",
    "    mean,\n",
    "    upper,\n",
    "    lower,\n",
    "    fname,\n",
    "    save_plots=False,\n",
    "    E_iso_vals=np.array([5e54, 2e55, 5e55]),\n",
    "    theta_vals=np.deg2rad(np.linspace(0,90,50)),\n",
    "    n=50\n",
    "):\n",
    "    Z_static = {\n",
    "        'jetType': -1,\n",
    "        'specType': 0,\n",
    "        'xi_N': 1.0,\n",
    "        'L0': 0.0, \n",
    "        'q': 0.0,\n",
    "        'ts': 0.0,\n",
    "        'p': 2.2,\n",
    "        'epsilon_e': 0.1,\n",
    "        'epsilon_B': 0.01,\n",
    "        'thetaCore': 0.1\n",
    "    }\n",
    "    \n",
    "    event_time = name_to_time(event)\n",
    "    source_meas = source.measurements\n",
    "    after_meas = source_meas.iloc[np.where(source_meas.dateobs>event_time)[0]]\n",
    "    \n",
    "    dist_vals = np.array([mean-lower, mean+upper])*u.Mpc\n",
    "    n_vals = np.logspace(-3,1,n)\n",
    "    \n",
    "    x = np.array((after_meas.dateobs-event_time)/pd.Timedelta(1, unit='d'))\n",
    "\n",
    "    t=pd.to_timedelta(x, unit='D').total_seconds()\n",
    "    \n",
    "    nu = 888e6\n",
    "    \n",
    "    meas = source.measurements\n",
    "    sigma = np.median(meas['flux_peak_err'])\n",
    "    upper_lims = sigma/50\n",
    "    run_calc(t, nu, upper_lims, E_iso_vals, dist_vals, theta_vals, n_vals, Z_static, fname)\n",
    "    make_plot(E_iso_vals, dist_vals, theta_vals, n_vals, fname, save_plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914b049a-332a-4600-92be-463f50f43995",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://docs.google.com/spreadsheets/d/e/2PACX-1vTPTtxWq4mVNiM5eKL_98a53O6-gQteS7Ab7kdIUqtwxsThLIR7yh60kPTTiwbw0pE45mXoZUYeBCWA/pub?output=csv')\n",
    "df = pd.read_csv(BytesIO(r.content), index_col=0)\n",
    "interesting = df[(df['Dougal classification'] == 'yes')]\n",
    "interesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d5f09f-091c-40b3-91bb-04caeeaa5181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lightcurve(source, event, save_fig=False):\n",
    "    event_time = name_to_time(event)\n",
    "    a = source.plot_lightcurve(start_date=pd.Timestamp(event_time), save=save_fig)\n",
    "    ax = a.gca()\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylim(bottom=min(x for x in source.measurements.flux_peak if x>0)/1.01)\n",
    "    plt.show()\n",
    "    plt.close(fig='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd98574-b517-40b0-be65-214d4dae47ec",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "for sid in interesting.index.values:\n",
    "    print(sid)\n",
    "    source = piperun.get_source(sid)\n",
    "    meas = source.measurements\n",
    "    \n",
    "    source_df = interesting[interesting.index == sid]\n",
    "    event = source_df.event.values[0]\n",
    "    mean, upper, lower = source_df[['Event Distance (Mpc)', 'Event Distance Upper (Mpc)', 'Event Distance Lower (Mpc)']].values[0]\n",
    "\n",
    "    \n",
    "    epoch_indices='all'\n",
    "    plot_lightcurve(source, event)\n",
    "    if sid == 5535012:\n",
    "        epoch_indices = [1,2,3,4,5,6,8,9]\n",
    "    elif sid == 4895153:\n",
    "        epoch_indices = [range(1,10)]\n",
    "    \n",
    "#     fit_afterglowpy(source, event, mean, fname=f'{sid}_{event}', save_plots=False, epoch_indices=epoch_indices)\n",
    "#     get_constraints(source, event, mean, upper, lower, fname=f'{sid}_{event}', save_plots=False, n=100)\n",
    "#     fit_bpl(source, event, mean, fname=f'{sid}_{event}', save_plots=False, epoch_indices=epoch_indices)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb5ff28-6fb0-4c53-b34b-2079a9b3b75b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
